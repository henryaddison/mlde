#!/usr/bin/env python
# setup jobs for training a model

import os
import subprocess
import sys

import typer

app = typer.Typer()


def train_cmd(sde, workdir, config, config_overrides=list):
    train_basecmd = ["python", f"bin/main.py"]

    train_opts = {
        "--config": f"src/ml_downscaling_emulator/score_sde_pytorch/configs/{sde}/{config}.py",
        "--workdir": workdir,
        "--mode": "train",
    }

    return (
        train_basecmd
        + [arg for item in train_opts.items() for arg in item]
        + config_overrides
    )


def queue_cmd(duration, memory):
    queue_basecmd = ["lbatch"]

    queue_opts = {
        "-a": os.getenv("HPC_PROJECT_CODE"),
        "-g": "1",
        "-m": str(memory),
        "-q": "cnu,gpu",
        "-t": str(duration),
        "--condaenv": "mv-mlde",
    }

    return queue_basecmd + [arg for item in queue_opts.items() for arg in item]


@app.command(
    context_settings={
        "allow_extra_args": True,
        "ignore_unknown_options": True,
    }
)
def main(
    ctx: typer.Context,
    model_run_id: str,
    sde: str,
    config: str = "ukcp_local_pr_12em_cncsnpp_continuous",
    memory: int = 64,
    duration: int = 72,
):
    # Add any other config on the commandline for training
    # --config.data.input_transform_key=spatial

    workdir = (
        f"{os.getenv('DERIVED_DATA')}/workdirs/score-sde/{sde}/{config}/{model_run_id}"
    )

    full_cmd = (
        queue_cmd(duration=duration, memory=memory)
        + ["--"]
        + train_cmd(sde, workdir, config, ctx.args)
    )
    print(" ".join(full_cmd).strip(), file=sys.stderr)
    output = subprocess.run(full_cmd, capture_output=True)
    print(output.stderr.decode("utf8").strip(), file=sys.stderr)
    print(output.stdout.decode("utf8").strip())


if __name__ == "__main__":
    app()
