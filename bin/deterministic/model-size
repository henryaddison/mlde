#!/usr/bin/env python
# calculate the number of parameters in a deterministic model

import logging
import os
from pathlib import Path

from ml_collections import config_dict
from mlde_utils.training.dataset import get_variables
import torch
import typer
import yaml


from ml_downscaling_emulator.deterministic.utils import create_model
from ml_downscaling_emulator.utils import model_size, param_count


logger = logging.getLogger()
logger.setLevel("INFO")

app = typer.Typer()


def load_config(config_path):
    logger.info(f"Loading config from {config_path}")
    with open(config_path) as f:
        config = config_dict.ConfigDict(yaml.unsafe_load(f))

    return config


def load_model(config):
    num_predictors = len(get_variables(config.data.dataset_name)[0])
    if config.data.time_inputs:
        num_predictors += 3
    model = torch.nn.DataParallel(
        create_model(config, num_predictors).to(device=config.device)
    )
    optimizer = torch.optim.Adam(model.parameters())
    state = dict(step=0, epoch=0, optimizer=optimizer, model=model)

    return state


@app.command()
def main(
    workdir: Path,
):
    config_path = os.path.join(workdir, "config.yml")
    config = load_config(config_path)
    model = load_model(config)["model"]
    num_score_model_parameters = param_count(model)

    typer.echo(f"Model has {num_score_model_parameters} parameters")

    size_all_mb = model_size(model)

    typer.echo("model size: {:.3f}MB".format(size_all_mb))


if __name__ == "__main__":
    app()
