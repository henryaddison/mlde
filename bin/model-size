#!/usr/bin/env python

import os
from pathlib import Path

from ml_collections import config_dict

import typer
import logging
import yaml

from ml_downscaling_emulator.score_sde_pytorch.models.location_params import (
    LocationParams,
)

from ml_downscaling_emulator.score_sde_pytorch.models import utils as mutils

from ml_downscaling_emulator.score_sde_pytorch.models import cncsnpp  # noqa: F401
from ml_downscaling_emulator.score_sde_pytorch.models import cunet  # noqa: F401

from ml_downscaling_emulator.score_sde_pytorch.models import (  # noqa: F401
    layerspp,  # noqa: F401
)  # noqa: F401
from ml_downscaling_emulator.score_sde_pytorch.models import layers  # noqa: F401
from ml_downscaling_emulator.score_sde_pytorch.models import (  # noqa: F401
    normalization,  # noqa: F401
)  # noqa: F401

logger = logging.getLogger()
logger.setLevel("INFO")

app = typer.Typer()


def load_model(config):
    logger.info(f"Loading model from config")
    score_model = mutils.get_model(config.model.name)(config)
    location_params = LocationParams(
        config.model.loc_spec_channels, config.data.image_size
    )

    return score_model, location_params


def load_config(config_path):
    logger.info(f"Loading config from {config_path}")
    with open(config_path) as f:
        config = config_dict.ConfigDict(yaml.unsafe_load(f))

    return config


@app.command()
def main(
    workdir: Path,
):
    config_path = os.path.join(workdir, "config.yml")
    config = load_config(config_path)
    score_model, location_params = load_model(config)
    num_score_model_parameters = sum(p.numel() for p in score_model.parameters())
    num_location_parameters = sum(p.numel() for p in location_params.parameters())

    typer.echo(f"Score model has {num_score_model_parameters} parameters")
    typer.echo(f"Location parameters have {num_location_parameters} parameters")


if __name__ == "__main__":
    app()
