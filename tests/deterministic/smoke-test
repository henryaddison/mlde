#! /usr/bin/env bash

set -euo pipefail

SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )

cpm_dataset="bham64_ccpm-4x_12em_psl-sphum4th-temp4th-vort4th_pr-historic"
gcm_dataset="bham64_gcm-4x_12em_psl-sphum4th-temp4th-vort4th_pr-historic"
workdir="output/test/unet/test-run"

config_path="src/ml_downscaling_emulator/deterministic/configs/ukcp_local_12em_pr_unet.py"

train_batch_size=2
epoch=2

rm -rf ${workdir}
WANDB_DISABLE_SERVICE=True WANDB_EXPERIMENT_NAME="test" python ${SCRIPT_DIR}/../../bin/deterministic/main.py --mode train --workdir ${workdir} --config ${config_path} --config.data.dataset_name=${cpm_dataset} --config.training.batch_size=${train_batch_size} --config.training.n_epochs=${epoch} --config.data.time_inputs=True --config.model.name=debug

num_samples=2
eval_batchsize=32

rm -rf "${workdir}/samples/epoch_${epoch}/${cpm_dataset}"
mlde evaluate sample ${workdir} --dataset ${cpm_dataset} --checkpoint epoch_${epoch} --batch-size ${eval_batchsize} --num-samples ${num_samples}
rm -rf "${workdir}/samples/epoch_${epoch}/${gcm_dataset}"
mlde evaluate sample ${workdir} --dataset ${gcm_dataset} --checkpoint epoch_${epoch} --batch-size ${eval_batchsize} --num-samples ${num_samples}
